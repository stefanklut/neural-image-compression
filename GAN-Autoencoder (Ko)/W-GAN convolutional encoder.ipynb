{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(os.getcwd())\n",
    "\n",
    "import time\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn.datasets\n",
    "\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image\n",
    "from torchvision.utils import make_grid\n",
    "import torchvision\n",
    "\n",
    "import scipy.misc\n",
    "from scipy.misc import imsave\n",
    "from IPython.display import display, clear_output\n",
    "from pyro.distributions.relaxed_straight_through import RelaxedBernoulliStraightThrough\n",
    "from torch.distributions.bernoulli import Bernoulli\n",
    "from torch.utils.data import RandomSampler, BatchSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1)\n",
    "use_cuda = torch.cuda.is_available()\n",
    "if use_cuda:\n",
    "    gpu = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIM = 64 # Model dimensionality\n",
    "BATCH_SIZE = 50 # Batch size\n",
    "CRITIC_ITERS = 8 # For WGAN and WGAN-GP, number of critic iters per gen iter\n",
    "LAMBDA = 10 # Gradient penalty lambda hyperparameter\n",
    "OUTPUT_DIM = 784 # Number of pixels in MNIST (28*28)\n",
    "DOWNLOAD_MNIST = False\n",
    "EPOCHS = 10\n",
    "DISC_GEN_TRAIN_RATIO = 5 # How many times the discriminator should be trained for one generator train\n",
    "FEATURE_LENGTH = 256 # How many binary values the encoded stage has\n",
    "LOAD_MODEL = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = datasets.MNIST(\n",
    "    root='./datasets/mnist/',\n",
    "    transform=torchvision.transforms.ToTensor(),\n",
    "    download=DOWNLOAD_MNIST,\n",
    "    train=True,\n",
    ")\n",
    "test_data = datasets.MNIST(\n",
    "    root='./datasets/mnist/',\n",
    "    transform=torchvision.transforms.ToTensor(),\n",
    "    download=False,\n",
    "    train=False,\n",
    ")\n",
    "\n",
    "# Data Loader for easy mini-batch return in training, the image batch shape will be (50, 1, 28, 28)\n",
    "trainloader = torch.utils.data.DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "trainloader2 = torch.utils.data.DataLoader(dataset=train_data, batch_size=100, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(dataset=test_data, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(28*28, 256),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "\n",
    "\n",
    "        preprocess = nn.Sequential(\n",
    "            nn.Linear(256, 4*4*4*DIM),\n",
    "            nn.ReLU(True),\n",
    "        )\n",
    "        block1 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(4*DIM, 2*DIM, 5),\n",
    "            nn.ReLU(True),\n",
    "        )\n",
    "        block2 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(2*DIM, DIM, 5),\n",
    "            nn.ReLU(True),\n",
    "        )\n",
    "        deconv_out = nn.ConvTranspose2d(DIM, 1, 8, stride=2)\n",
    "\n",
    "        self.block1 = block1\n",
    "        self.block2 = block2\n",
    "        self.deconv_out = deconv_out\n",
    "        self.preprocess = preprocess\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "\n",
    "    def forward(self, image_batch):\n",
    "        \n",
    "        encoded = self.encoder(image_batch)\n",
    "        bernoulli_encoded = RelaxedBernoulliStraightThrough(0.01, logits=encoded).rsample()\n",
    "        \n",
    "        output = self.preprocess(bernoulli_encoded)\n",
    "        output = output.view(-1, 4*DIM, 4, 4)\n",
    "        #print output.size()\n",
    "        output = self.block1(output)\n",
    "        #print output.size()\n",
    "        output = output[:, :, :7, :7]\n",
    "        #print output.size()\n",
    "        output = self.block2(output)\n",
    "        #print output.size()\n",
    "        output = self.deconv_out(output)\n",
    "        output = self.sigmoid(output)\n",
    "        #print output.size()\n",
    "        return output.view(-1, OUTPUT_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        main = nn.Sequential(\n",
    "            nn.Conv2d(1, DIM, 5, stride=2, padding=2),\n",
    "            # nn.Linear(OUTPUT_DIM, 4*4*4*DIM),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(DIM, 2*DIM, 5, stride=2, padding=2),\n",
    "            # nn.Linear(4*4*4*DIM, 4*4*4*DIM),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(2*DIM, 4*DIM, 5, stride=2, padding=2),\n",
    "            # nn.Linear(4*4*4*DIM, 4*4*4*DIM),\n",
    "            nn.ReLU(True),\n",
    "            # nn.Linear(4*4*4*DIM, 4*4*4*DIM),\n",
    "            # nn.LeakyReLU(True),\n",
    "            # nn.Linear(4*4*4*DIM, 4*4*4*DIM),\n",
    "            # nn.LeakyReLU(True),\n",
    "        )\n",
    "        self.main = main\n",
    "        self.output = nn.Linear(4*4*4*DIM, 1)\n",
    "\n",
    "    def forward(self, input):\n",
    "        input = input.view(-1, 1, 28, 28)\n",
    "        out = self.main(input)\n",
    "        out = out.view(-1, 4*4*4*DIM)\n",
    "        out = self.output(out)\n",
    "        return out.view(-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_gradient_penalty(netD, real_data, fake_data):\n",
    "    #print real_data.size()\n",
    "    alpha = torch.rand(BATCH_SIZE, 1)\n",
    "    alpha = alpha.expand(real_data.size())\n",
    "    alpha = alpha.cuda(gpu) if use_cuda else alpha\n",
    "\n",
    "    interpolates = alpha * real_data + ((1 - alpha) * fake_data)\n",
    "\n",
    "    if use_cuda:\n",
    "        interpolates = interpolates.cuda(gpu)\n",
    "    interpolates = autograd.Variable(interpolates, requires_grad=True)\n",
    "\n",
    "    disc_interpolates = netD(interpolates)\n",
    "\n",
    "    gradients = autograd.grad(outputs=disc_interpolates, inputs=interpolates,\n",
    "                              grad_outputs=torch.ones(disc_interpolates.size()).cuda(gpu) if use_cuda else torch.ones(\n",
    "                                  disc_interpolates.size()),\n",
    "                              create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "\n",
    "    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean() * LAMBDA\n",
    "    return gradient_penalty\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "netG = Generator()\n",
    "netD = Discriminator()\n",
    "\n",
    "if use_cuda:\n",
    "    netD = netD.cuda(gpu)\n",
    "    netG = netG.cuda(gpu)\n",
    "\n",
    "optimizerD = optim.Adam(netD.parameters(), lr=1e-4, betas=(0.5, 0.9))\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=1e-4, betas=(0.5, 0.9))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if LOAD_MODEL:\n",
    "    \n",
    "    checkpoint = torch.load('./models/models.pt')\n",
    "    netG.load_state_dict(checkpoint['netG_state_dict'])\n",
    "    netD.load_state_dict(checkpoint['netD_state_dict'])\n",
    "    optimizerG.load_state_dict(checkpoint['optimizerG_state_dict'])\n",
    "    optimizerD.load_state_dict(checkpoint['optimizerD_state_dict'])\n",
    "    loaded_epoch = checkpoint['epoch']\n",
    "\n",
    "    netG.eval()\n",
    "    netD.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myplot(x,y, name):\n",
    "    plt.clf()\n",
    "    plt.plot(x, y, 'ro')\n",
    "    plt.xlabel('iteration')\n",
    "    plt.ylabel(name)\n",
    "    plt.savefig('images/'+name+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(batch_size, feature_length):\n",
    "    p = torch.empty(batch_size, feature_length).uniform_(0, 1)\n",
    "    better_encoded = RelaxedBernoulliStraightThrough(0.01, logits=p).rsample()\n",
    "    return better_encoded #v.type(torch.IntTensor).type(torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Iteration 124 , epoch 3 , total iteration 3724'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "diterats = []\n",
    "giterats = []\n",
    "wdistarr = []\n",
    "dcostarr = []\n",
    "gcostarr = []\n",
    "trainloader_length = int(len(trainloader))\n",
    "\n",
    "if not LOAD_MODEL:\n",
    "    loaded_epoch = 0\n",
    "    \n",
    "for epoch in range(loaded_epoch, EPOCHS):\n",
    "    for i, (x,y) in enumerate(trainloader):\n",
    "\n",
    "        x = x.view(-1, 28*28)\n",
    "        if use_cuda:\n",
    "            x = x.cuda(gpu)\n",
    "            \n",
    "#         if i%(DISC_GEN_TRAIN_RATIO+1) != DISC_GEN_TRAIN_RATIO:\n",
    "        for iter_d in range(CRITIC_ITERS):\n",
    "\n",
    "            ############################\n",
    "            # (1) Update D network\n",
    "            ###########################\n",
    "\n",
    "            netD.zero_grad()\n",
    "\n",
    "            # train with real\n",
    "            D_real = netD(x).mean()\n",
    "            # print D_real\n",
    "\n",
    "            # train with fake\n",
    "\n",
    "            fake = netG(x).detach()\n",
    "            D_fake = netD(fake).mean()\n",
    "\n",
    "\n",
    "            # train with gradient penalty\n",
    "            gradient_penalty = calc_gradient_penalty(netD, x, fake)\n",
    "\n",
    "            D_cost = D_fake - D_real + gradient_penalty\n",
    "\n",
    "            D_cost.backward()\n",
    "\n",
    "            Wasserstein_D = D_real - D_fake\n",
    "            optimizerD.step()\n",
    "\n",
    "        diterats += [i+(epoch*trainloader_length)]\n",
    "        dcostarr += [D_cost.cpu().detach().numpy()]\n",
    "        wdistarr += [Wasserstein_D]\n",
    "\n",
    "        myplot(diterats, dcostarr, \"dcost\")\n",
    "        myplot(diterats, wdistarr, \"wdist\")\n",
    "\n",
    "\n",
    "        ############################\n",
    "        # (2) Update G network\n",
    "        ###########################\n",
    "\n",
    "        netG.zero_grad()\n",
    "\n",
    "        fake = netG(x)\n",
    "        G = netD(fake).mean()\n",
    "\n",
    "        G_cost = -G\n",
    "        G_cost.backward()\n",
    "\n",
    "        optimizerG.step()\n",
    "\n",
    "        # Write logs and save samples\n",
    "        giterats += [i+(epoch*trainloader_length)]\n",
    "        gcostarr += [G_cost.cpu().detach().numpy()]\n",
    "        myplot(giterats, gcostarr, \"gcost\")\n",
    "\n",
    "        if i % 50 == 49:\n",
    "            x, _ = next(iter(trainloader2))\n",
    "            x = x.view(-1, 28*28)\n",
    "            if use_cuda:\n",
    "                x = x.cuda(gpu)\n",
    "            fake = netG(x).unsqueeze(1).view(100,1,28,28)\n",
    "            if use_cuda:\n",
    "                fake = fake.cpu()\n",
    "                D_cost = D_cost.cpu()\n",
    "            save_image(fake, \"images/%d.png\" % (i+epoch*trainloader_length), nrow=10, normalize=False)\n",
    "            save_image(x.view(100,1,28,28), \"images/%d_original.png\" % (i+epoch*trainloader_length), nrow=10, normalize=False)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        clear_output(wait=True)\n",
    "        display('Iteration '+str(i)+' , epoch '+str(epoch)+' , total iteration '+str(i+(epoch*int((60000/BATCH_SIZE)))))\n",
    "        \n",
    "    torch.save({\n",
    "        'netG_state_dict': netG.state_dict(),\n",
    "        'netD_state_dict': netD.state_dict(),\n",
    "        'optimizerG_state_dict': optimizerG.state_dict(),\n",
    "        'optimizerD_state_dict': optimizerD.state_dict(),\n",
    "        'epoch': epoch,\n",
    "        }, './models/models3.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "checkpoint = torch.load('./models/models2.pt')\n",
    "netG.load_state_dict(checkpoint['netG_state_dict'])\n",
    "netD.load_state_dict(checkpoint['netD_state_dict'])\n",
    "\n",
    "netG.eval()\n",
    "netD.eval()\n",
    "\n",
    "original_pic = train_data.data[2]\n",
    "formatted_original = original_pic.view(-1, 28*28).type(torch.FloatTensor).cuda(gpu)/255\n",
    "generated_pic = netG(formatted_original)\n",
    "\n",
    "\n",
    "f = plt.figure()\n",
    "f.add_subplot(1,2, 1)\n",
    "plt.imshow(original_pic.numpy(), cmap='gray')\n",
    "f.add_subplot(1,2, 2)\n",
    "plt.imshow(generated_pic.cpu().view(28,28).detach().numpy(), cmap='gray')\n",
    "plt.show(block=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_encoded_file(encoded_array):\n",
    "    encoded_array = encoded_array[0].cpu().detach().numpy()\n",
    "    encoded_string = \"\".join(encoded_array.astype('int16').astype('str'))\n",
    "    data = [int(encoded_string[i:i+8], 2) for i in range(0,len(encoded_array),8)]\n",
    "    bytefile = bytes(data)\n",
    "    with open(\"myfile.bin\",\"wb\") as f:\n",
    "        f.write(bytefile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
