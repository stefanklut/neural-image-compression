{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(os.getcwd())\n",
    "\n",
    "import time\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn.datasets\n",
    "\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image\n",
    "from torchvision.utils import make_grid\n",
    "import torchvision\n",
    "\n",
    "import scipy.misc\n",
    "from scipy.misc import imsave\n",
    "from IPython.display import display, clear_output\n",
    "from pyro.distributions.relaxed_straight_through import RelaxedBernoulliStraightThrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1)\n",
    "use_cuda = torch.cuda.is_available()\n",
    "if use_cuda:\n",
    "    gpu = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIM = 64 # Model dimensionality\n",
    "BATCH_SIZE = 50 # Batch size\n",
    "CRITIC_ITERS = 8 # For WGAN and WGAN-GP, number of critic iters per gen iter\n",
    "LAMBDA = 10 # Gradient penalty lambda hyperparameter\n",
    "OUTPUT_DIM = 784 # Number of pixels in MNIST (28*28)\n",
    "DOWNLOAD_MNIST = False\n",
    "EPOCHS = 10\n",
    "DISC_GEN_TRAIN_RATIO = 5 # How many times the discriminator should be trained for one generator train\n",
    "FEATURE_LENGTH = 256 # How many binary values the encoded stage has"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = datasets.MNIST(\n",
    "    root='./datasets/mnist/',\n",
    "    transform=torchvision.transforms.ToTensor(),\n",
    "    download=DOWNLOAD_MNIST,\n",
    "    train=True,\n",
    ")\n",
    "test_data = datasets.MNIST(\n",
    "    root='./datasets/mnist/',\n",
    "    transform=torchvision.transforms.ToTensor(),\n",
    "    download=False,\n",
    "    train=False,\n",
    ")\n",
    "\n",
    "# Data Loader for easy mini-batch return in training, the image batch shape will be (50, 1, 28, 28)\n",
    "trainloader = torch.utils.data.DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(dataset=test_data, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "#         self.decoder = nn.Sequential(\n",
    "#             nn.Linear(128, 512),\n",
    "#             nn.Tanh(),\n",
    "#             nn.Linear(512, 28*28),\n",
    "#             nn.Sigmoid(),       # compress to a range (0, 1)\n",
    "#         )\n",
    "        \n",
    "\n",
    "        preprocess = nn.Sequential(\n",
    "            nn.Linear(128, 4*4*4*DIM),\n",
    "            nn.ReLU(True),\n",
    "        )\n",
    "        block1 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(4*DIM, 2*DIM, 5),\n",
    "            nn.ReLU(True),\n",
    "        )\n",
    "        block2 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(2*DIM, DIM, 5),\n",
    "            nn.ReLU(True),\n",
    "        )\n",
    "        deconv_out = nn.ConvTranspose2d(DIM, 1, 8, stride=2)\n",
    "\n",
    "        self.block1 = block1\n",
    "        self.block2 = block2\n",
    "        self.deconv_out = deconv_out\n",
    "        self.preprocess = preprocess\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, input):\n",
    "        \n",
    "        \n",
    "        \n",
    "        output = self.preprocess(input)\n",
    "        output = output.view(-1, 4*DIM, 4, 4)\n",
    "        #print output.size()\n",
    "        output = self.block1(output)\n",
    "        #print output.size()\n",
    "        output = output[:, :, :7, :7]\n",
    "        #print output.size()\n",
    "        output = self.block2(output)\n",
    "        #print output.size()\n",
    "        output = self.deconv_out(output)\n",
    "        output = self.sigmoid(output)\n",
    "        #print output.size()\n",
    "        return output.view(-1, OUTPUT_DIM)\n",
    "\n",
    "#         decoded = self.decoder(input)\n",
    "#         return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        main = nn.Sequential(\n",
    "            nn.Conv2d(1, DIM, 5, stride=2, padding=2),\n",
    "            # nn.Linear(OUTPUT_DIM, 4*4*4*DIM),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(DIM, 2*DIM, 5, stride=2, padding=2),\n",
    "            # nn.Linear(4*4*4*DIM, 4*4*4*DIM),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(2*DIM, 4*DIM, 5, stride=2, padding=2),\n",
    "            # nn.Linear(4*4*4*DIM, 4*4*4*DIM),\n",
    "            nn.ReLU(True),\n",
    "            # nn.Linear(4*4*4*DIM, 4*4*4*DIM),\n",
    "            # nn.LeakyReLU(True),\n",
    "            # nn.Linear(4*4*4*DIM, 4*4*4*DIM),\n",
    "            # nn.LeakyReLU(True),\n",
    "        )\n",
    "        self.main = main\n",
    "        self.output = nn.Linear(4*4*4*DIM, 1)\n",
    "\n",
    "    def forward(self, input):\n",
    "        input = input.view(-1, 1, 28, 28)\n",
    "        out = self.main(input)\n",
    "        out = out.view(-1, 4*4*4*DIM)\n",
    "        out = self.output(out)\n",
    "        return out.view(-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_gradient_penalty(netD, real_data, fake_data):\n",
    "    #print real_data.size()\n",
    "    alpha = torch.rand(BATCH_SIZE, 1)\n",
    "    alpha = alpha.expand(real_data.size())\n",
    "    alpha = alpha.cuda(gpu) if use_cuda else alpha\n",
    "\n",
    "    interpolates = alpha * real_data + ((1 - alpha) * fake_data)\n",
    "\n",
    "    if use_cuda:\n",
    "        interpolates = interpolates.cuda(gpu)\n",
    "    interpolates = autograd.Variable(interpolates, requires_grad=True)\n",
    "\n",
    "    disc_interpolates = netD(interpolates)\n",
    "\n",
    "    gradients = autograd.grad(outputs=disc_interpolates, inputs=interpolates,\n",
    "                              grad_outputs=torch.ones(disc_interpolates.size()).cuda(gpu) if use_cuda else torch.ones(\n",
    "                                  disc_interpolates.size()),\n",
    "                              create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "\n",
    "    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean() * LAMBDA\n",
    "    return gradient_penalty\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "netG = Generator()\n",
    "netD = Discriminator()\n",
    "\n",
    "if use_cuda:\n",
    "    netD = netD.cuda(gpu)\n",
    "    netG = netG.cuda(gpu)\n",
    "\n",
    "optimizerD = optim.Adam(netD.parameters(), lr=1e-4, betas=(0.5, 0.9))\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=1e-4, betas=(0.5, 0.9))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myplot(x,y, name):\n",
    "    plt.clf()\n",
    "    plt.plot(x, y, 'ro')\n",
    "    plt.xlabel('iteration')\n",
    "    plt.ylabel(name)\n",
    "    plt.savefig('images/'+name+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(batch_size, feature_length):\n",
    "    p = torch.empty(batch_size, feature_length).uniform_(0, 1)\n",
    "    #v = torch.bernoulli(p)\n",
    "    better_encoded = RelaxedBernoulliStraightThrough(0.01, logits=p).rsample()\n",
    "    return better_encoded #v.type(torch.IntTensor).type(torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Iteration 607 , epoch 2 , total iteration 3007'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "diterats = []\n",
    "giterats = []\n",
    "wdistarr = []\n",
    "dcostarr = []\n",
    "gcostarr = []\n",
    "for epoch in range(EPOCHS):\n",
    "    for i, (x,y) in enumerate(trainloader):\n",
    "        start_time = time.time()\n",
    "\n",
    "        x = x.view(-1, 28*28)\n",
    "#         if i%(DISC_GEN_TRAIN_RATIO+1) != DISC_GEN_TRAIN_RATIO:\n",
    "\n",
    "        ############################\n",
    "        # (1) Update D network\n",
    "        ###########################\n",
    "\n",
    "        for iter_d in range(CRITIC_ITERS):\n",
    "\n",
    "            if use_cuda:\n",
    "                x = x.cuda(gpu)\n",
    "\n",
    "            netD.zero_grad()\n",
    "\n",
    "            # train with real\n",
    "            D_real = netD(x).mean()\n",
    "            # print D_real\n",
    "\n",
    "            # train with fake\n",
    "            noise = generate_data(BATCH_SIZE, 128)\n",
    "            if use_cuda:\n",
    "                noise = noise.cuda(gpu)\n",
    "            fake = netG(noise).detach()\n",
    "            D_fake = netD(fake).mean()\n",
    "\n",
    "\n",
    "            # train with gradient penalty\n",
    "            gradient_penalty = calc_gradient_penalty(netD, x, fake)\n",
    "\n",
    "            D_cost = D_fake - D_real + gradient_penalty\n",
    "\n",
    "            D_cost.backward()\n",
    "\n",
    "            Wasserstein_D = D_real - D_fake\n",
    "            optimizerD.step()\n",
    "            \n",
    "        diterats += [i+(epoch*int(len(trainloader)))]\n",
    "        dcostarr += [D_cost.cpu().detach().numpy()]\n",
    "        wdistarr += [Wasserstein_D]\n",
    "\n",
    "        myplot(diterats, dcostarr, \"dcost\")\n",
    "        myplot(diterats, wdistarr, \"wdist\")\n",
    "\n",
    "#         else:\n",
    "        ############################\n",
    "        # (2) Update G network\n",
    "        ###########################\n",
    "\n",
    "        netG.zero_grad()\n",
    "\n",
    "        noise = generate_data(BATCH_SIZE, 128)\n",
    "        if use_cuda:\n",
    "            noise = noise.cuda(gpu)\n",
    "        fake = netG(noise)\n",
    "        G = netD(fake).mean()\n",
    "\n",
    "        G_cost = -G\n",
    "        G_cost.backward()\n",
    "\n",
    "        optimizerG.step()\n",
    "\n",
    "        # Write logs and save samples\n",
    "        giterats += [i+(epoch*int(len(trainloader)))]\n",
    "        gcostarr += [G_cost.cpu().detach().numpy()]\n",
    "        myplot(giterats, gcostarr, \"gcost\")\n",
    "            \n",
    "        if i % 100 == 99:\n",
    "            noise = generate_data(100, 128)\n",
    "            if use_cuda:\n",
    "                noise = noise.cuda(gpu)\n",
    "            fake = netG(noise).unsqueeze(1).view(100,1,28,28)\n",
    "            if use_cuda:\n",
    "                fake = fake.cpu()\n",
    "                D_cost = D_cost.cpu()\n",
    "            save_image(fake, \"images/%d.png\" % (i+epoch*int(len(trainloader))), nrow=10, normalize=False)\n",
    "            \n",
    "        \n",
    "        clear_output(wait=True)\n",
    "        display('Iteration '+str(i)+' , epoch '+str(epoch)+' , total iteration '+str(i+(epoch*int((60000/BATCH_SIZE)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
